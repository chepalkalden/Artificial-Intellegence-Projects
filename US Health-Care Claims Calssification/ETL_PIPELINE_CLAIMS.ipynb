{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wug5R9c8XlTFhsJ9gybBQR-aL_rh6LJR",
      "authorship_tag": "ABX9TyOFjhOfMX9VS/QUiUIc/YYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chepalkalden/Artificial-Intellegence-Projects/blob/main/US%20Health-Care%20Claims%20Calssification/ETL_PIPELINE_CLAIMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the data from CMS GOV into google drive"
      ],
      "metadata": {
        "id": "0glagvzasAld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb1g0OxR-aM-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create claims-categorization directory and a data subdirectory within it\n",
        "os.makedirs(\"/content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data\", exist_ok=True)\n",
        "\n",
        "# CMS ZIP URLs\n",
        "urls = {\n",
        "    \"benificiary\": \"https://www.cms.gov/research-statistics-data-and-systems/downloadable-public-use-files/synpufs/downloads/de1_0_2008_beneficiary_summary_file_sample_1.zip\",\n",
        "    \"carrier\": \"http://downloads.cms.gov/files/DE1_0_2008_to_2010_Carrier_Claims_Sample_1A.zip\",\n",
        "    \"inpatient\": \"https://www.cms.gov/research-statistics-data-and-systems/downloadable-public-use-files/synpufs/downloads/de1_0_2008_to_2010_inpatient_claims_sample_1.zip\",\n",
        "    \"outpatient\": \"https://www.cms.gov/research-statistics-data-and-systems/downloadable-public-use-files/synpufs/downloads/de1_0_2008_to_2010_outpatient_claims_sample_1.zip\",\n",
        "    \"drug\": \"http://downloads.cms.gov/files/DE1_0_2008_to_2010_Prescription_Drug_Events_Sample_1.zip\"\n",
        "}\n",
        "\n",
        "def download_and_extract(name, url):\n",
        "    zip_path = f\"/content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/{name}.zip\"\n",
        "    extract_path = f\"/content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/{name}\"\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"{name} data extracted to {extract_path}\")\n",
        "    return extract_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform & Feature Engineering"
      ],
      "metadata": {
        "id": "SINyRJa1sRkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_transform(df, claim_type):\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # Check if 'CLM_THRU_DT' exists before dropping NaNs and creating date features\n",
        "    if 'CLM_THRU_DT' in df.columns:\n",
        "        df = df.dropna(subset=['CLM_THRU_DT'])\n",
        "\n",
        "        # Date features\n",
        "        df['CLM_THRU_DT'] = pd.to_datetime(df['CLM_THRU_DT'], errors='coerce')\n",
        "        df['day_of_week'] = df['CLM_THRU_DT'].dt.dayofweek\n",
        "        df['month'] = df['CLM_THRU_DT'].dt.month\n",
        "    else:\n",
        "        print(f\"'CLM_THRU_DT' column not found in {claim_type} data. Skipping date feature creation.\")\n",
        "\n",
        "\n",
        "    # Normalize categorical features\n",
        "    for col in ['DGNS_CD_1', 'PRCDR_CD_1', 'PRVDR_NUM']:\n",
        "        if col in df.columns:\n",
        "            df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
        "\n",
        "    # Feature engineering: frequency of procedures\n",
        "    if 'PRCDR_CD_1' in df.columns:\n",
        "        proc_freq = df['PRCDR_CD_1'].value_counts().to_dict()\n",
        "        df['proc_freq'] = df['PRCDR_CD_1'].map(proc_freq)\n",
        "\n",
        "    df['claim_type'] = claim_type\n",
        "    return df"
      ],
      "metadata": {
        "id": "FUpufI1b_jdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Saving the cleaned data into Google Cloud"
      ],
      "metadata": {
        "id": "MK9Zlg5HsXi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_cleaned_data(df, name):\n",
        "    output_path = f\"/content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/cleaned_{name}.csv\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Saved cleaned {name} data to {output_path}\")\n"
      ],
      "metadata": {
        "id": "GWXjOAGg_n_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main constructor function to Run the ETL Pipeline"
      ],
      "metadata": {
        "id": "olghhH7nskFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    for name, url in urls.items():\n",
        "        path = download_and_extract(name, url)\n",
        "        csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
        "        if csv_files:\n",
        "            df = pd.read_csv(os.path.join(path, csv_files[0]), low_memory=False)\n",
        "            cleaned_df = clean_and_transform(df, claim_type=name)\n",
        "            save_cleaned_data(cleaned_df, name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3p1WHEh_uCO",
        "outputId": "7f6c9ac6-0447-4d70-d199-e074f82e72ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benificiary data extracted to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/benificiary\n",
            "'CLM_THRU_DT' column not found in benificiary data. Skipping date feature creation.\n",
            "Saved cleaned benificiary data to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/cleaned_benificiary.csv\n",
            "carrier data extracted to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/carrier\n",
            "Saved cleaned carrier data to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/cleaned_carrier.csv\n",
            "inpatient data extracted to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/inpatient\n",
            "Saved cleaned inpatient data to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/cleaned_inpatient.csv\n",
            "outpatient data extracted to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/outpatient\n",
            "Saved cleaned outpatient data to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/cleaned_outpatient.csv\n",
            "drug data extracted to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/drug\n",
            "'CLM_THRU_DT' column not found in drug data. Skipping date feature creation.\n",
            "Saved cleaned drug data to /content/drive/MyDrive/Colab Notebooks/Claims-Categorization/data/cleaned_drug.csv\n"
          ]
        }
      ]
    }
  ]
}